import cv2
import numpy as np
import os
import cv2 as cv
from scipy.spatial import KDTree
import open3d as o3d


def icp_2d(X, Y, max_iterations=100, tolerance=1e-5):
    """
    Perform ICP (Iterative Closest Point) algorithm in 2D.

    Parameters:
    X : numpy.ndarray
        The source point set (N x 2).
    Y : numpy.ndarray
        The target point set (N x 2).
    max_iterations : int, optional
        Maximum number of iterations. Default is 100.
    tolerance : float, optional
        Convergence criteria. Default is 1e-5.

    Returns:
    R : numpy.ndarray
        The rotation matrix (2 x 2).
    T : numpy.ndarray
        The translation vector (2,).
    """
    # Initialize transformation
    R = np.eye(2)
    T = np.zeros(2)

    for _ in range(max_iterations):
        # Find nearest neighbors
        tree = KDTree(Y)
        distances, indices = tree.query(X)

        # Compute centroid
        X_centroid = np.mean(X, axis=0)
        Y_centroid = np.mean(Y[indices], axis=0)

        # Compute covariance matrix
        H = np.dot((X - X_centroid).T, (Y[indices] - Y_centroid))

        # Singular Value Decomposition
        U, _, Vt = np.linalg.svd(H)

        # Calculate rotation matrix
        R = np.dot(U, Vt)

        # Calculate translation vector
        T = Y_centroid - np.dot(R, X_centroid)

        # Apply transformation to source points
        X_transformed = np.dot(X, R.T) + T

        # Check convergence
        if np.all(np.abs(X_transformed - Y[indices]) < tolerance):
            break

        # Update source points
        X = X_transformed

    return R, T

def save_xy_file(point_cloud, filename):
    # 提取点云数据的 x 和 y 坐标
    points_xy = np.asarray(point_cloud.points)[:, :2]

    # 将点云数据保存到 .xy 文件
    with open(filename, "w") as file:
        for point in points_xy:
            # 将每个点的 x、y 坐标写入文件，每行一个点
            file.write(f"{point[0]} {point[1]}\n")

def video_screen_shot():
    video_file = '14/dav/14/14-1-4.mp4'   # 输入影片檔案名稱
    output_folder = 'output_frames'   # 输出資料夾名稱
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    cap = cv2.VideoCapture(video_file) # 打開影片文件
    # check
    if not cap.isOpened():
        print("Error: Unable to open video file.")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)    # 取得影片幀率
    frame_interval = int(fps * 3)

    frame_count = 0
    total_frames = 0

    while cap.isOpened() and total_frames < 150:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_count % frame_interval == 0:
            # 存圖像
            frame_file = os.path.join(output_folder, f'frame_{total_frames}.jpg')
            cv2.imwrite(frame_file, frame)
            print(f'Frame {total_frames} saved.')
            total_frames += 1
        frame_count += 1
    cap.release()
    print('Video frames extraction completed.')

def MAP_Magnification():
    for kp in kp1:  #大地圖中最遠點與平均座標的距離
        img_keypoints.append(kp.pt)

    # 計算影像 img 的平均特徵點
    img_average_point = np.mean(img_keypoints, axis=0)

    print("影像 img 的平均特徵點:", img_average_point)

    # 初始化最大距離為負無窮大
    max_distance = float('-inf')
    farthest_point = None

    # 找出距離平均特徵點最遠的特徵點
    for kp in img_keypoints:
        distance = np.linalg.norm(np.array(kp) - img_average_point)
        if distance > max_distance:
            max_distance = distance
            farthest_point = kp

    print("img影像中距離平均特徵點最遠的特徵點:", farthest_point)
    print("距離:", max_distance)
    print("縮放比例:", distance3 / max_distance)


folder_name = "UAV_path"  # 定義文件夾名稱
current_dir = os.path.dirname(os.path.realpath(__file__))
folder_path = os.path.join(current_dir, folder_name)   # 使用os.path.join連接路径和文件夾名稱
if not os.path.exists(folder_path):   # 檢查是否存在
    os.mkdir(folder_path)
    print(f"文件夾 '{folder_path}' 已創建。")
else:
    print(f"文件夾 '{folder_path}' 已存在。")



# video_screen_shot()

MIN_MATCH_COUNT = 10
img3 = cv2.imread('14/jpg/14/23/23-1.jpg', 1) # trainImage
sift = cv2.SIFT_create() # 初始化 SIFT 檢測器

kp3, des3 = sift.detectAndCompute(img3, None) # 使用 SIFT 找到img3的關鍵點和描述子

# 定義 FLANN 參數
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
search_params = dict(checks=50)

flann = cv2.FlannBasedMatcher(index_params, search_params)  # 創建 FLANN 匹配器


all_boxes = []  # 儲存所有方框的座標
center_points = []  # 儲存所有中心點座標
target_points = []
matched_points = []

average_keypoints_in_boxes = []  # 儲存每個方框的平均特徵點
farthest_keypoints_in_boxes = []  # 儲存每個方框內距離平均特徵點最遠的特徵點
distances = []  # 儲存每個方框內最遠特徵點與平均特徵點之間的距離
img_keypoints = []  # 儲存影像 img 的所有特徵點座標
total_path = 0
frame_count = 2

for i in range(0, frame_count):
    img = cv2.imread(f'output_frames/frame_{i}.jpg', 1)  # queryImage
    # 使用 SIFT 找到關鍵點和描述子
    kp1, des1 = sift.detectAndCompute(img, None)
    # 進行特徵匹配
    matches = flann.knnMatch(des1, des3, k=2)

    # 根據 Lowe's ratio 測試存儲所有良好的匹配
    good = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good.append(m)

    # 執行 Homography 變換
    if len(good) > MIN_MATCH_COUNT:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp3[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)

        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)
        matchesMask = mask.ravel().tolist()

        h, w, d = img.shape
        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)
        dst = cv.perspectiveTransform(pts, M)

        x1, y1 = np.int32(dst[0][0])
        x2, y2 = np.int32(dst[1][0])
        x3, y3 = np.int32(dst[2][0])
        x4, y4 = np.int32(dst[3][0])
        center_x = (x1 + x2 + x3 + x4) / 4
        center_y = (y1 + y2 + y3 + y4) / 4

        # print("中心坐標為:", center_x, center_y)
        center_points.append((center_x, center_y))
        matched_points.append(src_pts.squeeze())
        target_points.append(dst_pts.squeeze())
        all_boxes.append(np.int32(dst))
        box_keypoints = []
        for kp in kp1: #局部影像的最遠點與平均座標距離
            kp_pt = np.array(kp.pt)
            if cv.pointPolygonTest(np.array(dst), kp_pt, False) >= 0:
                box_keypoints.append(kp.pt)
        box_keypoints = np.array(box_keypoints)
        avg_keypoint = np.mean(box_keypoints, axis=0)
        farthest_keypoint = box_keypoints[np.argmax(np.linalg.norm(box_keypoints - avg_keypoint, axis=1))]
        farthest_keypoints_in_boxes.append(farthest_keypoint)
        # 計算最遠特徵點與平均特徵點之間的距離
        distance3 = np.linalg.norm(farthest_keypoint - avg_keypoint)
        distances.append(distance3)
        print(f"方框 {i} 的平均特徵點: {avg_keypoint}")
        print(f"方框 {i}內距離平均特徵點最遠的特徵點: {farthest_keypoint}")
        print(f"方框{i} 距離3:{distance3}")

        MAP_Magnification()

        color = (0, 255, 0)  # BGR
        color2 = (0, 0, 255)  # BGR
        #將鏡頭框出來
        # for box in all_boxes:
        #     img3 = cv.polylines(img3, [box], True, color, 3, cv.LINE_AA)
        # 將所有中心點標示出來
        for point in center_points:
            center_x, center_y = map(int, point)
            cv.circle(img3, (center_x, center_y), radius=5, color=(255, 255, 255), thickness=25)
        # 將所有中心點連接成直線
        for i in range(len(center_points) - 1):
            cv.line(img3, tuple(map(int, center_points[i])), tuple(map(int, center_points[i + 1])), color2, 10)
        #存進檔案中
        frame_file = os.path.join('UAV_path', f'path_{total_path}.jpg')
        cv2.imwrite(frame_file, img3)
        total_path += 1
    else:
        print(f"Not enough matches are found in frame {i} - {len(good)}/{MIN_MATCH_COUNT}")





# 逐個處理每個方框
# for idx, box in enumerate(all_boxes):
#     # 提取方框的範圍
#     x, y, w, h = cv.boundingRect(box)
#
#     # 從原始圖像中提取方框內的圖像
#     cropped_img = img[y:y+h, x:x+w]
#
#     # 將提取的圖像保存為 JPG 文件
#     cv.imwrite(f"C:\\Users\\small\\yolov5-master\\img\\prtimg\\cropped_image_{idx}.jpg", cropped_img)


# 將特徵點的 x 和 y 坐標添加到點雲中，並將 z 坐標設置為 0
    point_cloud = o3d.geometry.PointCloud()
    target_point_cloud = o3d.geometry.PointCloud()
    for points in matched_points:
        # 將每個特徵點轉換為 3D 點
        points_3d = np.hstack((points, np.zeros((points.shape[0], 1), dtype=np.float32)))
        # 將 3D 點添加到點雲中
        point_cloud.points.extend(o3d.utility.Vector3dVector(points_3d))
    for points in target_points:
        # 將每個特徵點轉換為 3D 點
        target_points_3d = np.hstack((points, np.zeros((points.shape[0], 1), dtype=np.float32)))
        # 將 3D 點添加到點雲中
        target_point_cloud.points.extend(o3d.utility.Vector3dVector(target_points_3d))

    save_xy_file(point_cloud, 'point_cloud.xy')
    save_xy_file(target_point_cloud, 'target_point_cloud.xy')



